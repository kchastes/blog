> 《并发编程艺术》笔记

# 并发编程挑战

所涉及到的知识点：

1. 单核线程通过分配`CPU`时间片来实现多线程机制，线程切换的过程就叫做上下文切换。

2. 并发不一定比串行快，在任务量少时，可能由于上下文切换所带来的资源消耗拖累并发速度。

3. 减少上下文切换的方式：
  - 无锁并发编程，例如数据分段处理，不同线程处理不同段。
  - `CAS`算法：使用`CAS`算法更新数据，不需要加锁。
  - 非必要不要使用线程。
  - 协程：在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换。

4. 实战：

  ```she
  jstack 2519 > /tmp/dump17 # jump出线程信息
  grep java.lang.Thread.State dump17 | awk '{print $2$3$4$5}' | sort | uniq -c # 统计所有线程分别处于什么状态
  ```

5. 避免死锁方式：

  - 避免单个线程同时获取多个锁。
  - 避免在所内占用多个资源。
  - 尝试使用定时锁。

6. 资源限制：如果网速只有1Mb/s，开10个线程也不会变成10Mb/s，同时会增加上下文切换和资源调度的时间。

# Java并发底层原理

`Java`中所使用的并发机制依赖于`JVM`的实现和`CPU`的指令。

1. `volatile`保证内存可见性。在`Java`内存模型会确保所有线程看到一致的`volatile`变量值。原理在于加了`Volatile`标识的代码会多出一行`lock`汇编指令，该指令效果：将缓存行数据写回内存，同时使其他`cpu`缓存的数据无效。（依赖于缓存一致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态）

2. 追加字节避免头尾节点在同一缓存行中，从而影响写性能。这类优化只针对特定处理器，同时如果不是频繁的写，造成的性能影响不大，反而会带来读取更多的字节到缓存行中的性能影响。

3. `Synchonized`，代码块同步是使用`monitorenter`和`monitorexit`指令实现的，`monitorenter`指令是在编译后插入到同步代码块的开始位置，而`monitorexit`是插入到方法结束处和异常处(防止抛出异常锁未释放)。任何对象都有一个`monitor`与之关联。

   1. 对于普通同步方法，锁是当前实例对象。
   2. 对于静态同步方法，锁是当前类的Class对象。
   3. 对于同步方法块，锁是`Synchonized`括号里配置的对象。

   锁是存在对象头中的`Mark Word`中，存储的数据会随着锁标志位的变化而变化。

4. 偏向锁：基于锁一般由同一线程多次获得这一理论，偏向锁就是为了降低获取锁的代价。偏向锁会在对象头和栈帧中的锁记录里存储锁偏向的线程`ID`，通过这一属性区分锁释放偏向某一线程。

5. 轻量级锁会在当前线程的栈帧中创建锁记录空间，将对象头的`mark word`复制到该空间中，然后线程会将`mark word`替换为锁记录的指针，成功则加锁成功，失败则自旋重试。当存在锁竞争时会升级为重量级锁。重量级锁是阻塞等待，轻量级锁是自旋，适合同步代码执行快的程序(不容易形成竞争，就不会升级为重量级锁)

6. `Java`中的`CAS`就是使用了`CMPXCHG`命令。`CAS`存在的问题：

   - `ABA`问题：`A->B->A`此时会觉得并没有发生变化，通过版本号解决，`Java`中提供了`AtomicStampedReference`。
   - 循环时间大：如果长时间不成功，将会一直自旋，CPU消开销大。
   - 只能保证一个共享变量的原子操作。取巧办法：合并变量。`Java`提供了`AtomicReference`保证引用对象之间的原子性。
